{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01d73fc3",
   "metadata": {},
   "source": [
    "# Projet : Créer un modèle de scoring pour un organisme de crédit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eabc824",
   "metadata": {},
   "source": [
    "## Sommaire\n",
    "\n",
    "* [1. Observation des données et preprocessing (Kaggle)](#1)\n",
    "    * [1.1 Imports et fonctions d'analyse et de preprocessing](#1.1)\n",
    "    * [1.2 Observation des données déséquilibrées](#1.2)\n",
    "    * [1.3 Supression de features et catégorisation](#1.3)\n",
    "    * [1.4 Remplacement des valeurs nulles et des outliers](#1.4)\n",
    "    * [1.5 Observation des features finales](#1.5)\n",
    "* [2. Pipe de transformation](#2)\n",
    "* [3. Modélisations et MLFlow](#3)\n",
    "    * [3.1 DummyClassifier](#3.1)\n",
    "    * [3.2 LogisticRegressor](#3.2)\n",
    "    * [3.3 LightGBM](#3.3)\n",
    "    * [3.4 XGBoost](#3.4)\n",
    "    * [3.5 AdaBoost](#3.5)\n",
    "* [4. ROC-Curve, comparaison des meilleurs modèles](#4)\n",
    "* [5. Pipeline de référence](#5)\n",
    "* [6. Feature importance et interprétabilité (globale et locale)](#6)\n",
    "    * [6.1 Features les plus corrélées aux targets](#6.1)\n",
    "    * [6.2 Feature importance de LGBM](#6.2)\n",
    "    * [6.1 SHAP](#6.3)\n",
    "    * [6.1 LIME](#6.4)\n",
    "* [7. Analyse du Data Drift](#7)\n",
    "* [8. Réduction de la mémoire des datasets pour export vers Github](#8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ad9827",
   "metadata": {},
   "source": [
    "## 1. Observation des données et preprocessing (Kaggle) <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0daf0a",
   "metadata": {},
   "source": [
    "### 1.1 Imports et fonctions d'analyse et de preprocessing <a class=\"anchor\" id=\"1.1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c72cc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "# ----------------------------------------------------\n",
    "import sklearn\n",
    "import scipy\n",
    "import statsmodels.api as sm \n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# ----------------------------------------------------\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, FunctionTransformer\n",
    "\n",
    "# ----------------------------------------------------\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "# ----------------------------------------------------\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# ----------------------------------------------------\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc81496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_detect(df, col):\n",
    "    q1_col = Q1[col]\n",
    "    iqr_col = IQR[col]\n",
    "    q3_col = Q3[col]\n",
    "    return df[((df[col] < (q1_col - 1.5 * iqr_col)) |(df[col] > (q3_col + 1.5 * iqr_col)))]\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "def lower_outlier(df, col):\n",
    "    q1_col = Q1[col]\n",
    "    iqr_col = IQR[col]\n",
    "    q3_col = Q3[col]\n",
    "    lower = df[(df[col] < (q1_col - 1.5 * iqr_col))]\n",
    "    return lower\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "def upper_outlier(df, col):\n",
    "    q1_col = Q1[col]\n",
    "    iqr_col = IQR[col]\n",
    "    q3_col = Q3[col]\n",
    "    upper = df[(df[col] > (q3_col + 1.5 * iqr_col))]\n",
    "    return upper\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "def show_num_col(df, col):\n",
    "    print(\"*********************** {} ***********************\\n\".format(col))\n",
    "    print(\"lower outlier: {} ****** upper outlier: {}\\n\".format(lower_outlier(df,col).shape[0], \n",
    "                                                                upper_outlier(df,col).shape[0]))\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.subplot(2,1,1)\n",
    "    df[col].plot(kind='box', subplots=True, sharex=False, vert=False)\n",
    "    plt.subplot(2,1,2)\n",
    "    df[col].plot(kind='density', subplots=True, sharex=False)\n",
    "    plt.show()\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "def show_cat_col(df, col):\n",
    "    print(\"******************** {} ********************\\n\".format(col))\n",
    "    df[col].value_counts().plot(kind='bar')\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.show()\n",
    "    \n",
    "# ----------------------------------------------------------\n",
    "def replace_upper(df, col):\n",
    "    q1_col = Q1[col]\n",
    "    iqr_col = IQR[col]\n",
    "    q3_col = Q3[col]\n",
    "    tmp = 9999999\n",
    "    upper = q3_col + 1.5 * iqr_col\n",
    "    df[col] = df[col].where(lambda x: (x < (upper)), tmp)\n",
    "    df[col] = df[col].replace(tmp, upper)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "def replace_lower(df, col):\n",
    "    q1_col = Q1[col]\n",
    "    iqr_col = IQR[col]\n",
    "    q3_col = Q3[col]\n",
    "    tmp = 1111111\n",
    "    lower = q1_col - 1.5 * iqr_col\n",
    "    df[col] = df[col].where(lambda x: (x > (lower)), tmp)\n",
    "    df[col] = df[col].replace(tmp, lower)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "def replace_mode(df, col):\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    print(\"NaN de {} remplacés par le mode {}\".format(col, df[col].mode()[0]))\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "def replace_mean(df, col):\n",
    "    df[col] = df[col].fillna(df[col].mean())\n",
    "    print(\"NaN de {} remplacés par la moyenne {}\".format(col, df[col].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af28d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"application_train.csv\")\n",
    "test = pd.read_csv(\"application_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac32fcc6",
   "metadata": {},
   "source": [
    "### 1.2 Observation des données déséquilibrées <a class=\"anchor\" id=\"1.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e08873",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = \"TARGET\", data = train)\n",
    "train.loc[:, 'TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd29d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train[train['TARGET']==0])/len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e9f837",
   "metadata": {},
   "source": [
    "Données déséquilibrées : un peu plus de 8% de \"mauvais payeurs\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acc7d88",
   "metadata": {},
   "source": [
    "### 1.3 Supression de features et catégorisation <a class=\"anchor\" id=\"1.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d164a2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_train = len(train) * 0.60\n",
    "int(threshold_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655b4d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_test = len(test) * 0.60\n",
    "int(threshold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f75c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train:\\n\")\n",
    "print(train.columns[train.isna().sum() > int(threshold_train)])\n",
    "print(\"******************************************\")\n",
    "print(\"Test:\\n\")\n",
    "print(test.columns[test.isna().sum() > int(threshold_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0648b42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On restreint les features à celles qui sont renseignées pour plus de 60% des clients\n",
    "\n",
    "train_new = train.dropna(axis=1, thresh=threshold_train)\n",
    "print(train_new.shape)\n",
    "print(\"******************************************\")\n",
    "test_new = test.dropna(axis=1, thresh=threshold_test)\n",
    "print(test_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b096b4e",
   "metadata": {},
   "source": [
    "On sépare les features par types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf0d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feature = train_new.dtypes!=object\n",
    "final_numeric_feature = train_new.columns[numeric_feature].tolist()\n",
    "\n",
    "#----------------------------------------------------\n",
    "numeric_feature_test = test_new.dtypes!=object\n",
    "final_numeric_feature_test = test_new.columns[numeric_feature_test].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c07045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = train_new[final_numeric_feature]\n",
    "\n",
    "#-------------------------------------------\n",
    "numeric_test = test_new[final_numeric_feature_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec2b8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_features = numeric.dtypes==np.int64\n",
    "final_discrete_feature = numeric.columns[discrete_features].tolist()\n",
    "discrete = numeric[final_discrete_feature]\n",
    "\n",
    "#-------------------------------------------\n",
    "discrete_features_test = numeric_test.dtypes==np.int64\n",
    "final_discrete_feature_test = numeric_test.columns[discrete_features_test].tolist()\n",
    "discrete_test = numeric_test[final_discrete_feature_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65b79d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = numeric.dtypes==np.float64\n",
    "final_continuous_feature = numeric.columns[continuous_features].tolist()\n",
    "continuous = numeric[final_continuous_feature]\n",
    "\n",
    "#-------------------------------------------\n",
    "continuous_features_test = numeric_test.dtypes==np.float64\n",
    "final_continuous_feature_test = numeric_test.columns[continuous_features_test].tolist()\n",
    "continuous_test = numeric_test[final_continuous_feature_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ba17cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_col = continuous.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd8c5a6",
   "metadata": {},
   "source": [
    "### 1.4 Remplacement des valeurs nulles et des outliers <a class=\"anchor\" id=\"1.4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2f6ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(continuous_col)):\n",
    "    show_num_col(continuous[continuous_col], continuous_col[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34e497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_is_null = continuous.isna().sum() != 0\n",
    "final_continuous_feature = continuous.columns[continuous_is_null].tolist()\n",
    "print(\"Features continues pour le train: \\n\",final_continuous_feature)\n",
    "\n",
    "print(\"****************************************\")\n",
    "continuous_is_null_test = continuous_test.isna().sum() != 0\n",
    "final_continuous_feature_test = continuous_test.columns[continuous_is_null_test].tolist()\n",
    "print(\"Features continues pour le test: \\n\",final_continuous_feature_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ca78e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pour le train:\\n\")\n",
    "for i in range(len(final_continuous_feature)):\n",
    "    replace_mean(continuous, final_continuous_feature[i])\n",
    "\n",
    "print(\"************************************\")\n",
    "print(\"Pour le test:\\n\")\n",
    "for i in range(len(final_continuous_feature_test)):\n",
    "    replace_mean(continuous_test, final_continuous_feature_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc325cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric[continuous_col] = continuous[continuous_col]\n",
    "\n",
    "# ----------------------------------------------\n",
    "numeric_test[continuous_col] = continuous_test[continuous_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bfa9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = numeric.columns\n",
    "\n",
    "# ------------------------------------\n",
    "col_names_test = numeric_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32555f8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Nb d'outliers par colonne du train:\\n\")\n",
    "for i in range(len(col_names)):\n",
    "    print(\"{}: {}\".format(col_names[i],(outlier_detect(numeric,col_names[i]).shape[0])))\n",
    "    \n",
    "print(\"\\n\\n***************************************\\n\")\n",
    "print(\"Nb d'outliers par colonne du test:\\n\")\n",
    "for i in range(len(col_names_test)):\n",
    "    print(\"{}: {}\".format(col_names_test[i],(outlier_detect(numeric_test,col_names_test[i]).shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9026f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = train_new.quantile(0.25)\n",
    "Q3 = train_new.quantile(0.75)\n",
    "IQR = Q3 - Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb51df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier = []\n",
    "for i in range(len(final_numeric_feature)):\n",
    "    if outlier_detect(numeric[final_numeric_feature],final_numeric_feature[i]).shape[0] !=0:\n",
    "        outlier.append(final_numeric_feature[i])\n",
    "\n",
    "outlier_test = []\n",
    "for i in range(len(final_numeric_feature_test)):\n",
    "    if outlier_detect(numeric_test[final_numeric_feature_test],final_numeric_feature_test[i]).shape[0] !=0:\n",
    "        outlier_test.append(final_numeric_feature_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdba5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without TARGET field\n",
    "col_names = outlier_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9279fc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Outliers supérieurs pour le train:\\n\")\n",
    "for i in range(len(col_names)):\n",
    "    print(\"{}: {}\".format(col_names[i],(upper_outlier(numeric,col_names[i]).shape[0])))\n",
    "    \n",
    "print(\"\\n\\n****************************************\\n\")\n",
    "print(\"Outliers supérieurs pour le test:\\n\")\n",
    "for i in range(len(col_names)):\n",
    "    print(\"{}: {}\".format(col_names[i],(upper_outlier(numeric_test,col_names[i]).shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08462ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(col_names)):\n",
    "    replace_upper(numeric, col_names[i])   \n",
    "    \n",
    "#------------------------------------------------------\n",
    "for i in range(len(col_names)):\n",
    "    replace_upper(numeric_test, col_names[i])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90170c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Outliers inférieurs pour le train:\\n\")\n",
    "for i in range(len(col_names)):\n",
    "    print(\"{}: {}\".format(col_names[i],(lower_outlier(numeric,col_names[i]).shape[0])))\n",
    "    \n",
    "print(\"\\n\\n****************************************\\n\")\n",
    "print(\"Outliers inférieurs pour le test:\\n\")\n",
    "for i in range(len(col_names)):\n",
    "    print(\"{}: {}\".format(col_names[i],(lower_outlier(numeric_test,col_names[i]).shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581c48c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(col_names)):\n",
    "    replace_lower(numeric, col_names[i])\n",
    "    \n",
    "# #--------------------------------------------------\n",
    "for i in range(len(col_names)):\n",
    "    replace_lower(numeric_test, col_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fbfa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feature = train_new.dtypes==object\n",
    "final_categorical_feature = train_new.columns[categorical_feature].tolist()\n",
    "\n",
    "#----------------------------------------------------\n",
    "categorical_feature_test = test_new.dtypes==object\n",
    "final_categorical_feature_test = test_new.columns[categorical_feature_test].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16cb6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = train_new[final_categorical_feature]\n",
    "\n",
    "#---------------------------------------------\n",
    "categorical_test = test_new[final_categorical_feature_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35481f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names_cat = categorical.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598309ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(col_names_cat)):\n",
    "    show_cat_col(categorical, col_names_cat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e6bcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"unique number is = {}\\nunique values are: \\n{} \".format(len(train_new['ORGANIZATION_TYPE'].unique()), \n",
    "                                                               train_new['ORGANIZATION_TYPE'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fc98ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pour le train:\\n\")\n",
    "for i in range(len(col_names_cat)):\n",
    "    replace_mode(categorical, col_names_cat[i])\n",
    "\n",
    "print(\"\\n\\n****************************************\\n\")\n",
    "print(\"Pour le test:\\n\")\n",
    "for i in range(len(col_names_cat)):\n",
    "    replace_mode(categorical_test, col_names_cat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54580467",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical.drop(['ORGANIZATION_TYPE'], axis=1, inplace=True)\n",
    "# ---------------------------------------------\n",
    "categorical_test.drop(['ORGANIZATION_TYPE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94745c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder() \n",
    "categorical = categorical.apply(lambda col_names_cat: le.fit_transform(col_names_cat)) \n",
    "categorical_test = categorical_test.apply(lambda col_names_cat: le.fit_transform(col_names_cat)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b3ad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train: \",categorical.shape)\n",
    "print(\"Test: \",categorical_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849e6cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names_cat = categorical.columns\n",
    "col_names = numeric_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c023ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new[col_names_cat] = categorical[col_names_cat]\n",
    "train_new[col_names] = numeric[col_names]\n",
    "\n",
    "# ----------------------------------------------------\n",
    "test_new[col_names] = numeric_test[col_names]\n",
    "test_new[col_names_cat] = categorical_test[col_names_cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f83037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new.drop(['ORGANIZATION_TYPE'], axis=1, inplace=True)\n",
    "test_new.drop(['ORGANIZATION_TYPE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdc385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train: \",train_new.loc[train.duplicated()].shape)\n",
    "#--------------------------------------------------\n",
    "print(\"Test: \",test_new.loc[test.duplicated()].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3e3129",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_new.drop(\"TARGET\", axis = 1)\n",
    "y = train_new['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07426008",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()\n",
    "col = ['NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR',\n",
    "       'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'AMT_CREDIT',\n",
    "       'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE',\n",
    "       'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE',\n",
    "       'REGION_POPULATION_RELATIVE', 'DAYS_BIRTH', 'DAYS_EMPLOYED',\n",
    "       'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'FLAG_MOBIL', 'FLAG_EMP_PHONE',\n",
    "       'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL',\n",
    "       'OCCUPATION_TYPE', 'CNT_FAM_MEMBERS', 'REGION_RATING_CLIENT',\n",
    "       'REGION_RATING_CLIENT_W_CITY', 'WEEKDAY_APPR_PROCESS_START',\n",
    "       'HOUR_APPR_PROCESS_START', 'REG_REGION_NOT_LIVE_REGION',\n",
    "       'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION',\n",
    "       'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY',\n",
    "       'LIVE_CITY_NOT_WORK_CITY', 'EXT_SOURCE_2', 'EXT_SOURCE_3',\n",
    "       'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE',\n",
    "       'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE',\n",
    "       'DAYS_LAST_PHONE_CHANGE', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3',\n",
    "       'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6',\n",
    "       'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9',\n",
    "       'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12',\n",
    "       'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15',\n",
    "       'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18',\n",
    "       'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21',\n",
    "       'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY',\n",
    "       'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON',\n",
    "       'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR']\n",
    "\n",
    "x_train[col] = pd.DataFrame(scaler.fit_transform(x_train[col]))\n",
    "test_new[col] = pd.DataFrame(scaler.transform(test_new[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3266c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = x_train[['SK_ID_CURR']]\n",
    "test_id = test_new[['SK_ID_CURR']]\n",
    "x_train = x_train.drop(columns = 'SK_ID_CURR')\n",
    "test_new = test_new.drop(columns = 'SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a065c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id.to_csv('cust_num.csv')\n",
    "test_id.to_csv('new_cust_num.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7dfffd",
   "metadata": {},
   "source": [
    "### 1.5 Observation des features finales <a class=\"anchor\" id=\"1.5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff3b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_col = set(discrete.columns).intersection(col)\n",
    "\n",
    "plt.figure(figsize = (22, 22))\n",
    "mask = np.triu(np.ones_like(discrete[disc_col].corr()))\n",
    "\n",
    "sns.heatmap(discrete[disc_col].corr(),mask = mask, cmap = plt.cm.Spectral,square=True, annot = True)\n",
    "plt.title('Correlation Heatmap');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c3058",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_col = set(continuous.columns).intersection(col)\n",
    "\n",
    "plt.figure(figsize = (22, 22))\n",
    "mask = np.triu(np.ones_like(continuous[cont_col].corr()))\n",
    "\n",
    "sns.heatmap(continuous[cont_col].corr(),mask = mask, cmap = plt.cm.Spectral,square=True, annot = True)\n",
    "plt.title('Correlation Heatmap');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8e0b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = train.corr()['TARGET'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86572615",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Most Positive Correlations:\\n', correlations.tail(15))\n",
    "print('\\nMost Negative Correlations:\\n', correlations.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c146786",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x= train['DAYS_BIRTH']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af5aee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x= train['DAYS_LAST_PHONE_CHANGE']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e648b388",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x= train['REG_CITY_NOT_WORK_CITY']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d845e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x= train['OWN_CAR_AGE']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0392cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x= train['EXT_SOURCE_3']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeb04d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x= train_new['DAYS_EMPLOYED']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7912a67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(x= train_new['AMT_GOODS_PRICE']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3e3495",
   "metadata": {},
   "source": [
    "## 2. Pipe de transformation <a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390deb8d",
   "metadata": {},
   "source": [
    "Création d'un pipe de transformation synthétisant les transformations effectuées et sauvegarde des 70 features utilisées pour la modélisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332470c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = list(x_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdb2f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594a495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[col]\n",
    "\n",
    "numeric_features = X.select_dtypes(exclude='object').columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "imp_cat = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "imp_num = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "cat_transformer = Pipeline([('LabelImputer',imp_cat), ('Encoder',OrdinalEncoder())])\n",
    "numerical_transformer = Pipeline([('NumImputer',imp_num), ('Scaler',MinMaxScaler())])\n",
    "\n",
    "ct = ColumnTransformer([('Cat',cat_transformer,categorical_features),('Num',numerical_transformer,numeric_features)])\n",
    "\n",
    "ct = ct.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33049407",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(ct, 'col_transfo.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1d52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('transformer',ct)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d07a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(ct.transform(X), columns = X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c686455e",
   "metadata": {},
   "source": [
    "## 3. Modélisations et MLFlow <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6143ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from time import time\n",
    "from collections import Counter\n",
    "\n",
    "# ----------------------------------------------------\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ----------------------------------------------------\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_validate, cross_val_predict\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "# ----------------------------------------------------\n",
    "from sklearn import metrics as met\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, auc, roc_auc_score, roc_curve\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "kfold = StratifiedKFold(n_splits=5, random_state=100, shuffle=True)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "import joblib\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0787547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction de coût prenant en compte le fait qu'un faux positif coûte 10 fois plus cher qu'un faux négatif\n",
    "def cost_score(y_true,y_pred,fn_cost=10, fp_cost=1):\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    loss = fn * fn_cost + fp * fp_cost\n",
    "    score = loss\n",
    "    return score\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# fonction renvoyant le seuil optimal pour minimiser la fonction de coût\n",
    "def best_thresh(y_true, y_prob, fn_cost=10, fp_cost=1,step=0.0001):\n",
    "\n",
    "    cost_min = np.inf\n",
    "    opti_thresh = 0.0\n",
    "    for threshold in np.arange(0.0, 1.0, step):\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "        fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "        cost = fn * fn_cost + fp * fp_cost\n",
    "        if cost < cost_min:\n",
    "            cost_min = cost\n",
    "            opti_thresh = threshold\n",
    "\n",
    "    return opti_thresh\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# fonction de sélection des meilleurs modèles par RandomizeSearch \n",
    "# avec ou sans smote préalable (class_weight sinon et si possible)\n",
    "# optimisation du score AUC puis du score créé\n",
    "# identification des meilleurs seuils pour minimiser la fonction de coût\n",
    "def model_res(model, X, y, params, smote = False, disp = True):\n",
    "\n",
    "    model_name = str(type(model)).split('.')[-1][0:-2]\n",
    "    \n",
    "    if smote == True:\n",
    "        model_name += ' & smote'\n",
    "        pipeline = Pipeline(steps = [['smote', SMOTE(random_state = 11)],\n",
    "                                     ['classifier', model]])\n",
    "    else:\n",
    "        model_name += ' & class_weight'     \n",
    "        pipeline = model\n",
    "    \n",
    "    clf1 = RandomizedSearchCV(estimator = pipeline, param_distributions = params, scoring = 'roc_auc', cv = kfold, \n",
    "                              n_jobs=-1, random_state=100)\n",
    "    clf1.fit(X, y)\n",
    "\n",
    "    model1 = clf1.best_estimator_\n",
    "    hyperparams1 = clf1.best_params_    \n",
    "    start = time()\n",
    "    y_pred_proba1 = cross_val_predict(model1, X, y, cv=kfold, method='predict_proba')[:, 1]\n",
    "    end = time()\n",
    "    laps1 = (end - start)/5\n",
    "    \n",
    "    y_pred1 = (y_pred_proba1 >= 0.5).astype(int)    \n",
    "    accuracy=accuracy_score(y, y_pred1)\n",
    "    recall=recall_score(y,y_pred1)\n",
    "    precision=precision_score(y,y_pred1)\n",
    "    f1=f1_score(y,y_pred1)\n",
    "    rocauc=roc_auc_score(y,y_pred_proba1)\n",
    "    score = cost_score(y,y_pred1)    \n",
    "    scores1 = [accuracy, recall, precision, f1, rocauc, score, 0.5]\n",
    "    \n",
    "    thresh1 = best_thresh(y, y_pred_proba1)\n",
    "    y_pred1bis = (y_pred_proba1 >= thresh1).astype(int)\n",
    "    accuracy=accuracy_score(y, y_pred1bis)\n",
    "    recall=recall_score(y,y_pred1bis)\n",
    "    precision=precision_score(y,y_pred1bis)\n",
    "    f1=f1_score(y,y_pred1bis)\n",
    "    rocauc=roc_auc_score(y,y_pred_proba1)\n",
    "    score = cost_score(y,y_pred1bis)     \n",
    "    scores1bis = [accuracy, recall, precision, f1, rocauc, score, thresh1]\n",
    "    \n",
    "    scorer = met.make_scorer(cost_score, greater_is_better = False)\n",
    "    \n",
    "    clf2 = RandomizedSearchCV(estimator = pipeline, param_distributions = params, scoring = scorer, cv = kfold, \n",
    "                              n_jobs=-1, random_state=100)\n",
    "    clf2.fit(X, y)\n",
    "\n",
    "    model2 = clf2.best_estimator_\n",
    "    hyperparams2 = clf2.best_params_  \n",
    "    start = time()\n",
    "    y_pred_proba2 = cross_val_predict(model2, X, y, cv=kfold, method='predict_proba')[:, 1]\n",
    "    end = time()\n",
    "    laps2 = (end - start)/5\n",
    "    \n",
    "    y_pred2 = (y_pred_proba2 >= 0.5).astype(int)  \n",
    "    accuracy=accuracy_score(y, y_pred2)\n",
    "    recall=recall_score(y,y_pred2)\n",
    "    precision=precision_score(y,y_pred2)\n",
    "    f1=f1_score(y,y_pred2)\n",
    "    rocauc=roc_auc_score(y,y_pred_proba2)\n",
    "    score = cost_score(y,y_pred2)    \n",
    "    scores2 = [accuracy, recall, precision, f1, rocauc, score, 0.5]\n",
    "\n",
    "    thresh2 = best_thresh(y, y_pred_proba2)\n",
    "    y_pred2bis = (y_pred_proba2 >= thresh2).astype(int)\n",
    "    accuracy=accuracy_score(y, y_pred2bis)\n",
    "    recall=recall_score(y,y_pred2bis)\n",
    "    precision=precision_score(y,y_pred2bis)\n",
    "    f1=f1_score(y,y_pred2bis)\n",
    "    rocauc=roc_auc_score(y,y_pred_proba2)\n",
    "    score = cost_score(y,y_pred2bis)     \n",
    "    scores2bis = [accuracy, recall, precision, f1, rocauc, score, thresh2]    \n",
    "    \n",
    "    df = None\n",
    "    \n",
    "    if disp == True:\n",
    "\n",
    "        fpr1, tpr1, _ = roc_curve(y, y_pred_proba1)\n",
    "        fpr2, tpr2, _ = roc_curve(y, y_pred_proba2)\n",
    "        curve = plt.figure()\n",
    "        plt.plot(fpr1, tpr1, 'b', label = 'AUC score optimization AUC = %0.2f' % auc(fpr1, tpr1))\n",
    "        plt.plot(fpr2, tpr2, 'orange', label = 'Business score optimization AUC = %0.2f' % auc(fpr2, tpr2))\n",
    "        plt.plot([0, 1], [0, 1],'r--')\n",
    "        plt.xlim([0, 1])\n",
    "        plt.ylim([0, 1])\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.legend(loc = 'lower right')\n",
    "        plt.suptitle('Receiver Operating Characteristic')\n",
    "        \n",
    "        output1 = pd.DataFrame({'SK_ID_CURR': train_id.SK_ID_CURR, \n",
    "                               'TARGET': y_pred_proba1})\n",
    "        output2 = pd.DataFrame({'SK_ID_CURR': train_id.SK_ID_CURR, \n",
    "                               'TARGET': y_pred_proba2})\n",
    "        fig, ax = plt.subplots(1,1)        \n",
    "        sns.histplot(output1['TARGET'], ax = ax, color = 'blue', label = 'AUC score optimization')\n",
    "        sns.histplot(output2['TARGET'], ax = ax, color = 'orange', label = 'Business score optimization')\n",
    "        plt.legend()\n",
    "        plt.title('Probability Distribution')\n",
    "        plt.show()\n",
    "        \n",
    "        cm1 = met.confusion_matrix(y, y_pred1)\n",
    "        cm2 = met.confusion_matrix(y, y_pred2)\n",
    "        fig, ax = plt.subplots(1,2, figsize = (18,7))\n",
    "        sns.heatmap(cm1, annot=True,  fmt='', xticklabels = [\"0\", \"1\"] , \n",
    "                        yticklabels = [\"0\", \"1\"], ax = ax[0])\n",
    "        ax[0].set_title('AUC score optimization / threshold = 0.5')   \n",
    "        ax[0].set_ylabel('Actual')\n",
    "        ax[0].set_xlabel('Predicted')\n",
    "        sns.heatmap(cm2, annot=True,  fmt='', xticklabels = [\"0\", \"1\"] , \n",
    "                        yticklabels = [\"0\", \"1\"], ax = ax[1])\n",
    "        ax[1].set_title('Business score optimization / threshold = 0.5')\n",
    "        ax[1].set_ylabel('Actual')\n",
    "        ax[1].set_xlabel('Predicted')\n",
    "        plt.suptitle('Confusion Matrix')\n",
    "        plt.show()\n",
    "        \n",
    "        cm1bis = met.confusion_matrix(y, y_pred1bis)\n",
    "        cm2bis = met.confusion_matrix(y, y_pred2bis)\n",
    "        fig, ax = plt.subplots(1,2, figsize = (18,7))\n",
    "        sns.heatmap(cm1bis, annot=True,  fmt='', xticklabels = [\"0\", \"1\"] , \n",
    "                        yticklabels = [\"0\", \"1\"], ax = ax[0])\n",
    "        ax[0].set_title(f'AUC score optimization / threshold = {thresh1}')   \n",
    "        ax[0].set_ylabel('Actual')\n",
    "        ax[0].set_xlabel('Predicted')\n",
    "        sns.heatmap(cm2bis, annot=True,  fmt='', xticklabels = [\"0\", \"1\"] , \n",
    "                        yticklabels = [\"0\", \"1\"], ax = ax[1])\n",
    "        ax[1].set_title(f'Business score optimization / threshold = {thresh2}')\n",
    "        ax[1].set_ylabel('Actual')\n",
    "        ax[1].set_xlabel('Predicted')\n",
    "        plt.suptitle('Confusion Matrix')\n",
    "        plt.show()\n",
    "\n",
    "        print('Classification Report / AUC score Optimization \\n', met.classification_report(y, y_pred1), '\\n\\n',\n",
    "              'Classification Report / Business score Optimization \\n', met.classification_report(y, y_pred2))   \n",
    "\n",
    "        col = ['accuracy', 'precision', 'recall', 'f1-score', 'roc_auc', 'business_score', 'threshold', 'time']\n",
    "        model_name1 = model_name + ' (scoring AUC)'\n",
    "        model_name2 = model_name + ' (scoring Business)'\n",
    "        model_name1bis = model_name + ' (scoring AUC) / best thresh'\n",
    "        model_name2bis = model_name + ' (scoring Business) / best thresh'\n",
    "        dic_mod = {model_name1 : scores1 + [laps1], model_name1bis : scores1bis + [laps1],\n",
    "                   model_name2 : scores2 + [laps2], model_name2bis : scores2bis + [laps2]}\n",
    "        df = pd.DataFrame.from_dict(dic_mod, orient = 'index', columns = col)\n",
    "\n",
    "        display(df)        \n",
    "        \n",
    "    return df, (model1, model2), (hyperparams1, hyperparams2), (scores1, scores2, scores1bis, scores2bis), curve\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# fonction du MLFlow permettant d'enregistrer les expériences \n",
    "def run_mlflow_experiment(model, exp_name, fig_name, hyperparams, scores, time, curve):\n",
    "    plt.savefig(fig_name)\n",
    "    \n",
    "    if str(type(model)).split('.')[1] in ['sklearn', 'dummy', 'linear_model', 'ensemble']:\n",
    "        model_name = str(type(model)).split('.')[-1][0:-2]\n",
    "    else:\n",
    "        model_name = 'Smote' + '/' + str(type(model.named_steps['classifier'])).split('.')[-1][0:-2]\n",
    "    \n",
    "    # Nom de l'expérience\n",
    "    experiment_name = exp_name\n",
    "    \n",
    "    # Initialisation de l'expérience\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    # Démarrage d'un run\n",
    "    with mlflow.start_run(run_name = exp_name) as run:\n",
    "        \n",
    "        # Enregistrement des hyperparamètres\n",
    "        mlflow.log_params(hyperparams)\n",
    "        \n",
    "        # Enregistrement des métriques\n",
    "        mlflow.log_metric(\"Accuracy\", scores[0])\n",
    "        mlflow.log_metric(\"Precision\", scores[1])\n",
    "        mlflow.log_metric(\"Recall\", scores[2])\n",
    "        mlflow.log_metric(\"F1_score\", scores[3])\n",
    "        mlflow.log_metric(\"Auc_score\", scores[4])\n",
    "        mlflow.log_metric(\"Business_score\", scores[5])\n",
    "        mlflow.log_metric(\"Threshold\", scores[6])\n",
    "        mlflow.log_metric(\"Fit_time\", time)\n",
    "\n",
    "        # Enregistrement des graphiques\n",
    "        mlflow.log_figure(curve, artifact_file = fig_name)\n",
    "        \n",
    "        # Enregistrement du modèle entraîné\n",
    "        mlflow.sklearn.log_model(model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225ae477",
   "metadata": {},
   "source": [
    "### 3.1 DummyClassifier <a class=\"anchor\" id=\"3.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14af9747",
   "metadata": {},
   "source": [
    "Classifieur de référence pour comparer les scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ccdf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "df_dum_sm, model_dum_sm, params_dum_sm, scores_dum_sm, curve_dum_sm = model_res(dummy_clf, X, y, {}, smote = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88342f21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"stratified\")\n",
    "df_dum, model_dum, params_dum, scores_dum, curve_dum = model_res(dummy_clf, X, y, {}, smote = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f2ffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dum_final = pd.concat([df_dum, df_dum_sm])\n",
    "df_dum_final.sort_values(by = 'time', \n",
    "                        ascending = True).sort_values(by = ['roc_auc', \n",
    "                                                            'accuracy'], \n",
    "                                                      ascending = False).sort_values(by = 'business_score', \n",
    "                                                                                     ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d93533",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_mlflow_experiment(model_dum[1], \n",
    "                      'DummyClassifier_ref', 'dummy_roc.png', params_dum[1], scores_dum[1], 0.137990, curve_dum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4a9b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curve_dum.savefig('dummy_roc.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195fe2d8",
   "metadata": {},
   "source": [
    "### 3.2 LogisticRegressor <a class=\"anchor\" id=\"3.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec23ee5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "df_lr_sm, model_lr_sm, params_lr_sm, scores_lr_sm, curve_lr_sm = model_res(lr, X, y, {}, smote = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd826d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "df_lr, model_lr, params_lr, scores_lr, curve_lr = model_res(lr, X, y, {}, smote = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74020b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lr_final = pd.concat([df_lr, df_lr_sm])\n",
    "df_lr_final.sort_values(by = 'time', \n",
    "                        ascending = True).sort_values(by = ['roc_auc', \n",
    "                                                            'accuracy'], \n",
    "                                                      ascending = False).sort_values(by = 'business_score', \n",
    "                                                                                     ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245c14b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_mlflow_experiment(model_lr[1], \n",
    "                      'Best_LogReg_simple', 'logreg_roc.png', params_lr[1], scores_lr[3], 3.509839, curve_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04696b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curve_lr.savefig('logreg_roc.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a06c9cb",
   "metadata": {},
   "source": [
    "### 3.3 LightGBM <a class=\"anchor\" id=\"3.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7e5069",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_lgb = {'learning_rate':[0.2,0.1,0.01,0.05,0.001],\n",
    "              'num_leaves':range(10,100,10),\n",
    "              'min_child_samples':range(500,1000,100),\n",
    "              'reg_alpha':[0.1,0.01,0.2,0.3],\n",
    "              'reg_lambda':[0.1,0.01,0.2,0.3],\n",
    "             'n_estimators':range(50,300,50),\n",
    "              'max_bin': range(500,1500,100)}\n",
    "\n",
    "param_lgb2 = {}\n",
    "for key in param_lgb.keys():\n",
    "    param_lgb2['classifier__'+key] = param_lgb[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f97ffde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_lgb_sm, model_lgb_sm, params_lgb_sm, scores_lgb_sm, curve_lgb_sm = model_res(LGBMClassifier(random_state = 100, \n",
    "                                                                                                   n_jobs=-1),\n",
    "                                                                                    X, y, param_lgb2, smote = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18a0378",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_lgb, model_lgb, params_lgb, scores_lgb, curve_lgb = model_res(LGBMClassifier(random_state = 100, n_jobs=-1,\n",
    "                                                                                class_weight = 'balanced'), \n",
    "                                                                 X, y, param_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a142d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lgb_final = pd.concat([df_lgb, df_lgb_sm])\n",
    "df_lgb_final.sort_values(by = 'time', \n",
    "                        ascending = True).sort_values(by = ['roc_auc', \n",
    "                                                            'accuracy'], \n",
    "                                                      ascending = False).sort_values(by = 'business_score', \n",
    "                                                                                     ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86d5790",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_mlflow_experiment(model_lgb[0], \n",
    "                      'Best_LGMClassifier', 'lgbm_roc.png', params_lgb[0], scores_lgb[2], 2.363127, curve_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e0fc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curve_lgb.savefig('lgbm_roc.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b98718",
   "metadata": {},
   "source": [
    "### 3.4 XGBoost <a class=\"anchor\" id=\"3.4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe2fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_xgb = {'learning_rate':[0.2,0.1,0.01,0.05,0.001],\n",
    "              'subsample':[1,0.5,0.2,0.1],\n",
    "              'max_depth' : range(2,11,1),\n",
    "              'n_estimators':range(50,300,50)}\n",
    "\n",
    "param_xgb2 = {}\n",
    "for key in param_xgb.keys():\n",
    "    param_xgb2['classifier__'+key] = param_xgb[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754ff449",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_xgb_sm, model_xgb_sm, params_xgb_sm, scores_xgb_sm, curve_xg_sm = model_res(XGBClassifier(random_state = 100, n_jobs=-1), \n",
    "                                                                                X, y, param_xgb2, smote = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5d0038",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(y)\n",
    "estimate = counter[0] / counter[1]\n",
    "print('Estimate: %.3f' % estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b0501e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_xgb, model_xgb, params_xgb, scores_xgb, curve_xgb = model_res(XGBClassifier(random_state = 100, n_jobs=-1, \n",
    "                                                                               scale_pos_weight = estimate), \n",
    "                                                                 X, y, param_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fb5293",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xgb_final = pd.concat([df_xgb, df_xgb_sm])\n",
    "df_xgb_final.sort_values(by = 'time', \n",
    "                        ascending = True).sort_values(by = ['roc_auc', \n",
    "                                                            'accuracy'], \n",
    "                                                      ascending = False).sort_values(by = 'business_score', \n",
    "                                                                                     ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6f5841",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_mlflow_experiment(model_xgb[0], \n",
    "                      'Best_XGBClassifier', 'xgb_roc.png', params_xgb[0], scores_xgb[2], 34.514814, curve_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1deade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curve_xgb.savefig('xgb_roc.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6e9760",
   "metadata": {},
   "source": [
    "### 3.5 AdaBoost <a class=\"anchor\" id=\"3.5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a937ec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ada = {'learning_rate':[0.2,0.1,0.01,0.05,0.001],\n",
    "              'algorithm': ['SAMME', 'SAMME.R'],\n",
    "              'n_estimators':range(50,300,50)}\n",
    "\n",
    "param_ada2 = {}\n",
    "for key in param_ada.keys():\n",
    "    param_ada2['classifier__'+key] = param_ada[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7649e0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ada, model_ada, params_ada, scores_ada, curve_ada = model_res(AdaBoostClassifier(random_state = 100), \n",
    "                                                                 X, y, param_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f96f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ada_sm, model_ada_sm, params_ada_sm, scores_ada_sm, curve_ada_sm = model_res(AdaBoostClassifier(random_state = 100), \n",
    "                                                                                X, y, param_ada2, smote = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24856d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ada_final = pd.concat([df_ada, df_ada_sm])\n",
    "df_ada_final.sort_values(by = 'time', \n",
    "                        ascending = True).sort_values(by = ['roc_auc', \n",
    "                                                            'accuracy'], \n",
    "                                                      ascending = False).sort_values(by = 'business_score', \n",
    "                                                                                     ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeef129",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_mlflow_experiment(model_ada[1], \n",
    "                      'Best_AdaBoostClassifier', 'ada_roc.png', params_ada[1], scores_ada[3], 182.060805, curve_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffcbd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curve_ada.savefig('ada_roc.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb774f3",
   "metadata": {},
   "source": [
    "## 4. ROC-Curve, comparaison des meilleurs modèles <a class=\"anchor\" id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c823e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_df = [df_dum_final, df_lr_final, df_ada_final, df_xgb_final, df_lgb_final]\n",
    "df_comp = pd.DataFrame()\n",
    "for df in liste_df:\n",
    "    df= df.reset_index()\n",
    "    df = df.sort_values(by = 'time', \n",
    "                        ascending = True).sort_values(by = ['roc_auc', \n",
    "                                                            'accuracy'], \n",
    "                                                      ascending = False).sort_values(by = 'business_score', \n",
    "                                                                                     ascending = True)\n",
    "    df_comp = pd.concat([df_comp, df.head(1)])\n",
    "df_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c6483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model_dum[1], model_lr[1], model_ada[1], model_xgb[0], model_lgb[0]]\n",
    "\n",
    "result_table = pd.DataFrame(columns=['models', 'fpr','tpr','auc'])\n",
    "\n",
    "for model in models:\n",
    "    yproba = model.predict_proba(X)[::,1]\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y,  yproba)\n",
    "    aucroc = roc_auc_score(y, yproba)\n",
    "    \n",
    "    result_table = result_table.append({'models':model.__class__.__name__,\n",
    "                                        'fpr':fpr, \n",
    "                                        'tpr':tpr, \n",
    "                                        'auc':aucroc}, ignore_index=True)\n",
    "\n",
    "result_table.set_index('models', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2636e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "for i in result_table.index:\n",
    "    plt.plot(result_table.loc[i]['fpr'], \n",
    "             result_table.loc[i]['tpr'], \n",
    "             label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc'])\n",
    "             )\n",
    "    \n",
    "plt.plot([0,1], [0,1], color='orange', linestyle='--')\n",
    "\n",
    "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.xlabel(\"False positive rate\", fontsize=15)\n",
    "\n",
    "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.ylabel(\"True positive rate\", fontsize=15)\n",
    "\n",
    "plt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\n",
    "plt.legend(prop={'size':13}, loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f880793e",
   "metadata": {},
   "source": [
    "Le meilleur classifieur LGBM sera retenu ; il est par ailleurs beaucoup plus rapide que XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ade5db",
   "metadata": {},
   "source": [
    "## 5. Pipeline de référence <a class=\"anchor\" id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09a9f2a",
   "metadata": {},
   "source": [
    "Combinaison du pipe de transformation enregistré et du modèle entraîné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a3efeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfo = joblib.load('col_transfo.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da35dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98134218",
   "metadata": {},
   "outputs": [],
   "source": [
    "logged_model = 'runs:/e46c27c6fbfe4fd3884be624f3f7cad3/LGBMClassifier'\n",
    "model_ref = mlflow.sklearn.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ce18d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4c6eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipe = Pipeline([('transformer',transfo), ('model', model_ref)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b21bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(final_pipe, 'model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7706b34",
   "metadata": {},
   "source": [
    "## 6. Feature importance et interprétabilité (globale et locale) <a class=\"anchor\" id=\"6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b659da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_test = joblib.load('model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f34718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = pipe_test.predict_proba(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bda79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = train.copy()\n",
    "train_test['proba'] = pd.DataFrame(y_pred_test)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0f5c73",
   "metadata": {},
   "source": [
    "### 6.1 Features les plus corrélées aux targets <a class=\"anchor\" id=\"6.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ec3476",
   "metadata": {},
   "source": [
    "On reprend les features les plus corrélées aux targets pour observer la répartition des clients de référence au regard de la probabilité que le modèle leur aurait donnée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed12990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x='DAYS_BIRTH', y='proba', hue='TARGET', data=train_test)\n",
    "sns.kdeplot(x='DAYS_BIRTH', y='proba', data=train_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b82accb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=train_test, x=\"DAYS_BIRTH\", y=\"proba\", hue=\"TARGET\", fill=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec3f762",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x='DAYS_LAST_PHONE_CHANGE', y='proba', hue='TARGET', data=train_test)\n",
    "sns.kdeplot(x='DAYS_LAST_PHONE_CHANGE', y='proba', data=train_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703a3419",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=train_test, x=\"DAYS_LAST_PHONE_CHANGE\", y=\"proba\", hue=\"TARGET\", fill=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba675a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x='REG_CITY_NOT_WORK_CITY', y='proba', hue='TARGET', data=train_test)\n",
    "sns.kdeplot(x='REG_CITY_NOT_WORK_CITY', y='proba', data=train_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b45d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=train_test, x=\"REG_CITY_NOT_WORK_CITY\", y=\"proba\", hue=\"TARGET\", fill=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9069dda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x='OWN_CAR_AGE', y='proba', hue='TARGET', data=train_test)\n",
    "sns.kdeplot(x='OWN_CAR_AGE', y='proba', data=train_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1cb93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=train_test, x=\"OWN_CAR_AGE\", y=\"proba\", hue=\"TARGET\", fill=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e526dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x='EXT_SOURCE_3', y='proba', hue='TARGET', data=train_test)\n",
    "sns.kdeplot(x='EXT_SOURCE_3', y='proba', data=train_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1acee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=train_test, x=\"EXT_SOURCE_3\", y=\"proba\", hue=\"TARGET\", fill=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494bf7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x='DAYS_EMPLOYED', y='proba', hue='TARGET', data=train_test)\n",
    "sns.kdeplot(x='DAYS_EMPLOYED', y='proba', data=train_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb95883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=train_test, x=\"DAYS_EMPLOYED\", y=\"proba\", hue=\"TARGET\", fill=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664baf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x='AMT_GOODS_PRICE', y='proba', hue='TARGET', data=train_test)\n",
    "sns.kdeplot(x='AMT_GOODS_PRICE', y='proba', data=train_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83be437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=train_test, x=\"AMT_GOODS_PRICE\", y=\"proba\", hue=\"TARGET\", fill=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7352a7ff",
   "metadata": {},
   "source": [
    "### 6.2 Feature importance de LGBM <a class=\"anchor\" id=\"6.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c7d7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_feat = pd.DataFrame(pipe_test[1].feature_importances_, index = X.columns).sort_values(by = 0, ascending = False)\n",
    "fig, ax = plt.subplots()\n",
    "sns.barplot(x=df_feat.head(20)[0], y=df_feat.head(20).index, ax = ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5da50a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('Feat_importance.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a97201",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_proba = pipe_test.predict_proba(test)\n",
    "test_test = test.copy()\n",
    "test_test['proba'] = pd.DataFrame(y_pred_test_proba)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1ef385",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_test.loc[0, 'proba']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf296e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for feat in df_feat.head(4).index:\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    sns.scatterplot(x=feat, y ='proba', hue = 'TARGET', data = train_test, ax = ax)\n",
    "    x_min, x_max, y_min, y_max = plt.axis()\n",
    "    plt.hlines(y = 0.5157, xmin = x_min, xmax = x_max, color = 'red')\n",
    "    xp = test_test.loc[0, feat]\n",
    "    yp = test_test.loc[0, 'proba']\n",
    "    plt.plot(xp, yp, marker = 'o', color = 'green')\n",
    "    plt.xticks(rotation = 45, ha = 'right');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e1b474",
   "metadata": {},
   "source": [
    "Regardons si la réduction du dataset de train à 50% change l'allure des graphs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d681bfb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_samp, X_samp = train_test_split(train_test, test_size = 0.5, stratify = train_test[['TARGET']])\n",
    "\n",
    "for feat in df_feat.head(4).index:\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    sns.scatterplot(x=feat, y ='proba', hue = 'TARGET', data = train_samp, ax = ax)\n",
    "    x_min, x_max, y_min, y_max = plt.axis()\n",
    "    plt.hlines(y = 0.5157, xmin = x_min, xmax = x_max, color = 'red')\n",
    "    xp = test_test.loc[0, feat]\n",
    "    yp = test_test.loc[0, 'proba']\n",
    "    plt.plot(xp, yp, marker = 'o', color = 'green')\n",
    "    plt.xticks(rotation = 45, ha = 'right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeffe44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in df_feat.head(3).index:\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    sns.boxplot(x= 'TARGET', y = feat, data = train_test)\n",
    "    xp = test_test.loc[0, feat]\n",
    "    plt.plot(0, xp, marker = 'o', color = 'green');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030e711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in df_feat.head(3).index:\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    sns.boxplot(x= 'TARGET', y = feat, data = train_samp)\n",
    "    xp = test_test.loc[0, feat]\n",
    "    plt.plot(0, xp, marker = 'o', color = 'green');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c81a17",
   "metadata": {},
   "source": [
    "On considère que l'on pourra utiliser le dataset réduit pour l'explicabilité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d115c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp.to_csv('new_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a209749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(train['SK_ID_CURR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ec2fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(test['SK_ID_CURR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d75ecca",
   "metadata": {},
   "source": [
    "### 6.3 SHAP <a class=\"anchor\" id=\"6.3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a31187",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(pipe_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee470ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_shap = pd.DataFrame(pipe_test[0].transform(train[col]), columns = col)\n",
    "shap_val = explainer.shap_values(X_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a07df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = shap.summary_plot(shap_val, X_shap, show = False)\n",
    "plt.savefig('Shap_exp.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6589f03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_shap2 = pd.DataFrame(pipe_test[0].transform(train_samp[col]), columns = col)\n",
    "shap_val2 = explainer.shap_values(X_shap2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54be6aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_val2, X_shap2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fd5778",
   "metadata": {},
   "source": [
    "L'explainer de Shap est plus stable que celui du modèle. On préférera donc SHAP pour l'interprétabilité globale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7328f07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shap = pd.DataFrame(shap_val2[0], columns = X_shap2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef7f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = np.abs(df_shap.values).mean(0)\n",
    "shap_importance = pd.DataFrame(list(zip(col, vals)), columns=['col_name', 'feature_importance_vals'])\n",
    "shap_importance.sort_values(by=['feature_importance_vals'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161ed635",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(shap_importance['col_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f072ee94",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_val[1], X_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed54202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_val2[0], X_shap2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c246d2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"EXT_SOURCE_3\", shap_val[0], X_shap, interaction_index=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e614a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"EXT_SOURCE_2\", shap_val[0], X_shap, interaction_index=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb1c8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"DAYS_BIRTH\", shap_val[0], X_shap, interaction_index=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812445a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"CODE_GENDER\", shap_val[0], X_shap, interaction_index=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f59009",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"AMT_ANNUITY\", shap_val[0], X_shap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9b0e07",
   "metadata": {},
   "source": [
    "Pour l'explicabilité locale, il est nécessaire d'avoir fait travaillé l'explainer sur les données individuelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cf551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_test[1].predict_proba(pd.DataFrame(X_shap.iloc[0]).T)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61d44ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5921c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value[0], shap_val[0][0], X_shap.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc69793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value[0], shap_val[0][0:1000], X_shap.iloc[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4055ab8b",
   "metadata": {},
   "source": [
    "### 6.4 LIME <a class=\"anchor\" id=\"6.4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356fd311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "from lime.lime_tabular import LimeTabularExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025bfa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lime_explainer = LimeTabularExplainer(pipe_test[0].transform(train[col]), \n",
    "                                                       feature_names=col, \n",
    "                                                       class_names=['0', '1'], \n",
    "                                                       verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51620b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[0,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655d205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_data = pipe_test[0].transform(pd.DataFrame(test.loc[0,col]).T)\n",
    "lime_explanation = lime_explainer.explain_instance(transform_data[0], pipe_test[1].predict_proba)\n",
    "\n",
    "# Extract feature importance values\n",
    "feature_importance = {}\n",
    "for feature, importance in lime_explanation.as_list():\n",
    "    feature_importance[feature] = importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a48e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1270d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_explanation.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c12c45",
   "metadata": {},
   "source": [
    "Avec LIME, les features les plus importantes sont légèrement différentes mais on retrouve tout de même les principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02794a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_explanation.as_pyplot_figure();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c3a34c",
   "metadata": {},
   "source": [
    "En revanche, contrairement à Shap, il est possible d'interpréter la position d'un client inconnu sans avoir à le rentrer dans l'explainer... On choisira donc Shap pour l'interprétabilité locale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3185a6",
   "metadata": {},
   "source": [
    "## 7. Analyse du Data Drift <a class=\"anchor\" id=\"7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bda308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset, TargetDriftPreset, DataQualityPreset, RegressionPreset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381b837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = Report(metrics=[\n",
    "    DataDriftPreset(), \n",
    "])\n",
    "\n",
    "report.run(reference_data=train.drop(columns='TARGET'), current_data=test)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc91b0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.save_html('data_drift_report.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e80e579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on se limite ici aux 70 features utilisées\n",
    "\n",
    "report2 = Report(metrics=[\n",
    "    DataDriftPreset(), \n",
    "])\n",
    "\n",
    "report2.run(reference_data=train[col], current_data=test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a564cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "report2.save_html('data_drift_model_feat.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf23884",
   "metadata": {},
   "source": [
    "Il n'y a pas de Data Drift."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c544ae3",
   "metadata": {},
   "source": [
    "Regardons l'importance relative des features qui ont un léger drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3bd186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "dic_report = json.loads(report2.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913970a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_report.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e40eff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "drifted_feat = dic_report['metrics'][1]['result']['drift_by_columns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7199596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_drift = {}\n",
    "for feat in drifted_feat.keys():\n",
    "    if drifted_feat[feat]['drift_detected'] == True:\n",
    "        dico_drift[feat] = round(drifted_feat[feat]['drift_score'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ec780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdbec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "drift_col = list(dico_drift.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25590e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for columns in drift_col:\n",
    "    fig, ax = plt.subplots(1,2, figsize = (15, 4))\n",
    "    sns.histplot(train[columns], bins = 50, ax = ax[0])\n",
    "    ax[0].set_title('Initial data')\n",
    "    ax[0].set_xlabel('')\n",
    "    ax[0].set_ylabel('')\n",
    "    sns.histplot(test[columns], bins = 50, ax = ax[1])\n",
    "    ax[1].set_title('New data')\n",
    "    ax[1].set_xlabel('')\n",
    "    ax[1].set_ylabel('')\n",
    "    plt.suptitle(f'{columns} / drift_score = {dico_drift[columns]} / importance_rank = {list(df_feat.index).index(columns)}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607eef0c",
   "metadata": {},
   "source": [
    "Les features qui ont un léger drift ne sont pas parmi les proncipales permettant d'expliquer la classification.  \n",
    "Les nouveaux clients peuvent donc être considérés par le modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b7c2ad",
   "metadata": {},
   "source": [
    "## 8. Réduction de la taille des datasets pour export vers Github <a class=\"anchor\" id=\"8\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e384015b",
   "metadata": {},
   "source": [
    "Github classique n'acceptant pas les gros fichiers, il est nécessaire de les réduire autant que possible pour les exporter afin de les utiliser pour le déploiement. Nous créons donc de nouveaux fichiers csv moins lourds, en retypant les colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e4ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df):\n",
    "  \n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69de7a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_ref = col + ['TARGET', 'proba', 'SK_ID_CURR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ad2851",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train = reduce_memory_usage(train_test[col + ['TARGET', 'proba', 'SK_ID_CURR']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42377228",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_test = reduce_memory_usage(test_test[col + ['proba', 'SK_ID_CURR']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba843e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_samp, train_samp = train_test_split(app_train, test_size = 0.24, stratify = train_test[['TARGET']])\n",
    "end_mem = train_samp.memory_usage().sum() / 1024**2\n",
    "print('Finale memory usage for train: {:.2f} MB'.format(end_mem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c4a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp.to_csv('new_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf8bfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_test.to_csv('application_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47896697",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "696a02d0b6355968ae1c1488ef83e4a5ea6aa38603528b935ca878b2812b9edb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
